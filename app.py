import streamlit as st
import os
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import AIMessage, HumanMessage

# --- 1. ì´ˆê¸° ë¦¬ì†ŒìŠ¤ ë¡œë“œ (DB, ë‹¨ì¼ LLM) ---
@st.cache_resource
def load_resources():
    """
    API í‚¤ ì„¤ì •, 3ê°œì˜ ë²¡í„° DB(ICT, TP, LAW) ë¡œë“œ, ë‹¨ì¼ LLM ëª¨ë¸('flash' ë²„ì „)ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    """
    try:
        os.environ['GOOGLE_API_KEY'] = st.secrets["GOOGLE_API_KEY"]
    except Exception:
        st.error("Streamlit Secretsì— GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()

    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    
    # 3ê°œì˜ ë¶„ë¦¬ëœ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ëª¨ë‘ ë¡œë“œí•©ë‹ˆë‹¤.
    ict_retriever = FAISS.load_local("./faiss_index_ict", embeddings, allow_dangerous_deserialization=True).as_retriever(search_kwargs={'k': 5})
    tp_retriever = FAISS.load_local("./faiss_index_tp", embeddings, allow_dangerous_deserialization=True).as_retriever(search_kwargs={'k': 5})
    law_retriever = FAISS.load_local("./faiss_index_law", embeddings, allow_dangerous_deserialization=True).as_retriever(search_kwargs={'k': 5})
    
    # ë¬´ë£Œ ë²„ì „ì¸ 'flash' ëª¨ë¸ í•˜ë‚˜ë§Œ ìƒì„±í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash-latest", temperature=0.3)
    
    # ì´ 4ê°œì˜ ë³€ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (ë¦¬íŠ¸ë¦¬ë²„ 3ê°œ, LLM 1ê°œ)
    return ict_retriever, tp_retriever, law_retriever, llm

# --- 2. ì²´ì¸ ë° í”„ë¡¬í”„íŠ¸ ì •ì˜ ---
def setup_chains(llm):
    """
    í•˜ë‚˜ì˜ LLMì„ ì‚¬ìš©í•˜ì—¬ 2ê°œì˜ í•µì‹¬ ì²´ì¸ì„ ì •ì˜í•©ë‹ˆë‹¤.
    """
    # ì²´ì¸ 1: ì§ˆë¬¸ ì¬êµ¬ì„± ì²´ì¸ (ê¼¬ë¦¬ ì§ˆë¬¸ ì²˜ë¦¬ìš©)
    rewrite_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", "ì´ì „ ëŒ€í™” ë‚´ìš©ê³¼ ì‚¬ìš©ìì˜ ìµœê·¼ ì§ˆë¬¸ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤. ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•´ì•¼ë§Œ ì´í•´í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì´ë¼ë©´, ëŒ€í™” ë‚´ìš© ì—†ì´ë„ ì´í•´í•  ìˆ˜ ìˆëŠ” ë…ë¦½ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ì¬êµ¬ì„±í•´ì£¼ì„¸ìš”. ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì€ ì ˆëŒ€ í•˜ì§€ ë§ê³ , ì˜¤ì§ ì§ˆë¬¸ì„ ì¬êµ¬ì„±í•˜ëŠ” ì—­í• ë§Œ ìˆ˜í–‰í•˜ì„¸ìš”."),
            ("user", "{chat_history}"),
            ("human", "{input}"),
        ]
    )
    rewrite_chain = rewrite_prompt | llm | StrOutputParser()

    # ì²´ì¸ 2: ìµœì¢… ë‹µë³€ ìƒì„± ì²´ì¸ (ê³„ì¸µì  ìš°ì„ ìˆœìœ„ ì§€ì‹œ í¬í•¨)
    final_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", """ë‹¹ì‹ ì€ ì „ë¶í…Œí¬ë…¸íŒŒí¬ì˜ ê·œì •ê³¼ ìƒìœ„ ë²•ë¥ ì— ëª¨ë‘ í†µë‹¬í•œ ìµœê³ ì˜ AI ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•  ë•Œ, ì•„ë˜ì˜ [ì •ë³´ í™œìš© ê·œì¹™]ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤.

[ì •ë³´ í™œìš© ê·œì¹™]
1.  **ìµœìš°ì„  ìˆœìœ„:** [ICT ê¸°ê¸ˆ ì§€ì¹¨]ì— ê´€ë ¨ ë‚´ìš©ì´ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸í•˜ê³ , ë‚´ìš©ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í•´ë‹¹ ì§€ì¹¨ì„ ê·¼ê±°ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
2.  **2ì°¨ ìˆœìœ„:** [ICT ê¸°ê¸ˆ ì§€ì¹¨]ì— ëª…í™•í•œ ë‚´ìš©ì´ ì—†ì„ ê²½ìš°, [ì „ë¶ TP ê·œì •]ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤.
3.  **ì°¸ê³ ìš©:** [ìƒìœ„ ë²•ë¥ (ì„¸ë²•, íšŒê³„ê¸°ì¤€)]ì€ ìš©ì–´ì˜ ì •ì˜ë¥¼ ëª…í™•íˆ í•˜ê±°ë‚˜, ë‹¤ë¥¸ ë‘ ê·œì •ì— ë‚´ìš©ì´ ì—†ì„ ë•Œ ì¼ë°˜ì ì¸ ì›ì¹™ì„ ì„¤ëª…í•˜ê¸° ìœ„í•´ì„œë§Œ ì°¸ê³ í•©ë‹ˆë‹¤.
4.  ë‹µë³€ ì‹œ, ì–´ë–¤ ê·œì •ì„ ê·¼ê±°ë¡œ ë‹µë³€í•˜ëŠ”ì§€ ëª…ì‹œí•´ì£¼ë©´ ì‹ ë¢°ë„ê°€ ë†’ì•„ì§‘ë‹ˆë‹¤. (ì˜ˆ: "ICT ê¸°ê¸ˆ ì§€ì¹¨ ì œOì¡°ì— ë”°ë¼...")

---
[ICT ê¸°ê¸ˆ ì§€ì¹¨]:
{ict_context}

[ì „ë¶ TP ê·œì •]:
{tp_context}

[ìƒìœ„ ë²•ë¥ (ì„¸ë²•, íšŒê³„ê¸°ì¤€)]:
{law_context}
"""),
            ("user", "{chat_history}"),
            ("human", "{input}"),
        ]
    )
    final_chain = final_prompt | llm | StrOutputParser()
    
    return rewrite_chain, final_chain

# --- 3. ë©”ì¸ ë¡œì§ ì‹¤í–‰ í•¨ìˆ˜ ---
def get_response(user_input, chat_history, retrievers, chains):
    rewrite_chain, final_chain = chains
    ict_retriever, tp_retriever, law_retriever = retrievers

    rewritten_question = rewrite_chain.invoke({"input": user_input, "chat_history": chat_history})
    
    ict_docs = ict_retriever.invoke(rewritten_question)
    tp_docs = tp_retriever.invoke(rewritten_question)
    law_docs = law_retriever.invoke(rewritten_question)
    
    final_answer = final_chain.invoke({
        "ict_context": "\n".join([doc.page_content for doc in ict_docs]),
        "tp_context": "\n".join([doc.page_content for doc in tp_docs]),
        "law_context": "\n".join([doc.page_content for doc in law_docs]),
        "chat_history": chat_history,
        "input": user_input
    })
    
    return final_answer

# --- Streamlit UI ì„¤ì • ---
st.set_page_config(page_title="ìµœì¢… ê·œì • ì§ˆì˜ì‘ë‹µ ì±—ë´‡", page_icon="ğŸ›ï¸")
st.title("ğŸ›ï¸ ìµœì¢… ê·œì • ì§ˆì˜ì‘ë‹µ ì±—ë´‡")
st.info("ICTì§€ì¹¨ > TPê·œì • > ìƒìœ„ë²• ìˆœì„œë¡œ ë‹µë³€í•˜ë©°, ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•©ë‹ˆë‹¤.")

try:
    # ìˆ˜ì •ëœ ë¶€ë¶„: ì´ì œ 4ê°œì˜ ë³€ìˆ˜ë§Œ ë°›ìŠµë‹ˆë‹¤.
    ict_retriever, tp_retriever, law_retriever, llm = load_resources()
    # ìˆ˜ì •ëœ ë¶€ë¶„: ì´ì œ í•˜ë‚˜ì˜ llmë§Œ ì „ë‹¬í•©ë‹ˆë‹¤.
    rewrite_chain, final_chain = setup_chains(llm)

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    for message in st.session_state.chat_history:
        if isinstance(message, HumanMessage):
            with st.chat_message("user"): st.markdown(message.content)
        elif isinstance(message, AIMessage):
            with st.chat_message("assistant"): st.markdown(message.content)

    if prompt := st.chat_input("ê·œì •ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”..."):
        st.session_state.chat_history.append(HumanMessage(content=prompt))
        with st.chat_message("user"): st.markdown(prompt)

        with st.spinner("ë‹µë³€ì„ ìƒê°í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            answer = get_response(prompt, st.session_state.chat_history, (ict_retriever, tp_retriever, law_retriever), (rewrite_chain, final_chain))
            
            st.session_state.chat_history.append(AIMessage(content=answer))
            with st.chat_message("assistant"): st.markdown(answer)

except Exception as e:
    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n\nì˜¤ë¥˜ ìƒì„¸: {e}")
