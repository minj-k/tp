import streamlit as st
import os
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.documents import Document # Document íƒ€ì…ì„ ëª…ì‹œí•˜ê¸° ìœ„í•´ ì¶”ê°€

# --- ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì³ì£¼ëŠ” í•¨ìˆ˜ ---
def format_docs(docs: list[Document]) -> str:
    """ê²€ìƒ‰ëœ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©í•©ë‹ˆë‹¤."""
    return "\n\n".join(doc.page_content for doc in docs)
# ---------------------------------------------------


# --- ì´ˆê¸° ì„¤ì • (ë¯¸ë¦¬ ë§Œë“¤ì–´ì§„ ë²¡í„°DB ë¡œë“œ) ---
@st.cache_resource
def load_rag_chain():
    try:
        os.environ['GOOGLE_API_KEY'] = st.secrets["GOOGLE_API_KEY"]
    except Exception as e:
        st.error("Streamlit Secretsì— GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()

    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    vectorstore = FAISS.load_local("./faiss_index", embeddings, allow_dangerous_deserialization=True)
    st.sidebar.success("ì„ë² ë”© DB ë¡œë“œ ì™„ë£Œ!", icon="âœ…")

    retriever = vectorstore.as_retriever(search_kwargs={'k': 5})
    prompt_template_str = """
    ë‹¹ì‹ ì€ ì „ë¶í…Œí¬ë…¸íŒŒí¬ì˜ ê·œì •ê³¼ ì¬ì • ì§€ì¹¨ì„ ë¶„ì„í•˜ì—¬ ëª…í™•í•œ ê²°ë¡ ì„ ë‚´ë¦° í›„ ì§€ì›ì‚¬ì—…ì˜ ì§€ì›ì„ ë°›ëŠ” íšŒì‚¬ ì‚¬ëŒì—ê²Œ ì •í™•í•œ ë‹µë³€ì„ í•´ì£¼ëŠ” ë² í…Œë‘ ì‚¬ì—…ë‹´ë‹¹ìì´ì ì¹œì ˆí•˜ê³ ë„ ì •í™•í•œ ë¶„ì„ê°€ AIì…ë‹ˆë‹¤.
    ì•„ë˜ì˜ í”„ë¡œì„¸ìŠ¤ì— ë”°ë¼ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

    [í”„ë¡œì„¸ìŠ¤]
    1.  **ê³µê°ê³¼ í™•ì¸:** ë¨¼ì € ì‚¬ìš©ìì˜ ì§ˆë¬¸ ë‚´ìš©ì„ í™•ì¸í•˜ë©° "ë„¤, ~ì— ëŒ€í•´ ë¬¸ì˜í•˜ì…¨êµ°ìš”. ë‹µë³€í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤." ì™€ ê°™ì´ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.
    2.  **í•µì‹¬ ë‹µë³€:** ì œê³µëœ [Context]ì˜ ê·œì •ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ í•µì‹¬ì ì¸ ë‹µë³€ì„ ëª…í™•í•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.
    3.  **"í”ŒëŸ¬ìŠ¤ ì•ŒíŒŒ" ì •ë³´ ì œê³µ (ê°€ì¥ ì¤‘ìš”):** ë‹¨ìˆœíˆ ê·œì •ë§Œ ì•Œë ¤ì£¼ëŠ” ê²ƒì„ ë„˜ì–´, ë‹´ë‹¹ìë¡œì„œ ì¶”ê°€ì ìœ¼ë¡œ ë„ì›€ì´ ë  ë§Œí•œ ì •ë³´ë¥¼ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤.
        - **"ê·¸ë˜ì„œ ì´ì œ ë­˜ í•´ì•¼ í•˜ë‚˜ìš”?"** ì— ëŒ€í•œ ë‹µ: í•„ìš”í•œ ì ˆì°¨, ë‹¤ìŒ ë‹¨ê³„ ë“±ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.
        - **"ë¬´ì—‡ì´ í•„ìš”í•œê°€ìš”?"** ì— ëŒ€í•œ ë‹µ: ì œì¶œí•´ì•¼ í•  ì„œë¥˜, ì¤€ë¹„ë¬¼ ë“±ì„ ì•Œë ¤ì¤ë‹ˆë‹¤.
        - **"ì£¼ì˜í•  ì ì€ ì—†ë‚˜ìš”?"** ì— ëŒ€í•œ ë‹µ: ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜, ìœ ì˜ì‚¬í•­, ì•Œì•„ë‘ë©´ ì¢‹ì€ íŒ ë“±ì„ ì–¸ê¸‰í•©ë‹ˆë‹¤.
    4.  **ì¹œì ˆí•œ ë§ˆë¬´ë¦¬:** "ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë‹¤ì‹œ ë¬¼ì–´ë´ ì£¼ì„¸ìš”." ì™€ ê°™ì´ ëŒ€í™”ë¥¼ ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤.
    5.  **ì–´ì¡°:** ì‹œì¢…ì¼ê´€ ì¹œì ˆí•˜ê³  ìƒëƒ¥í•˜ë©°, ì‹ ë¢°ê° ìˆëŠ” ì „ë¬¸ê°€ì˜ ì–´ì¡°ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤. ë”±ë”±í•œ 'ì˜ˆ/ì•„ë‹ˆì˜¤'ë¡œ ì‹œì‘í•˜ì§€ ë§ˆì„¸ìš”.
    [Context]
    {context}

    [Question]
    {question}

    Answer:
    """
    prompt = PromptTemplate.from_template(prompt_template_str)
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash-latest", temperature=0.2)

    # --- RAG ì²´ì¸ êµ¬ì„± (ìˆ˜ì •ëœ ë¶€ë¶„) ---
    rag_chain = (
        # retrieverì˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ format_docs í•¨ìˆ˜ë¡œ ë„˜ê²¨ ë¬¸ìì—´ë¡œ ë³€í™˜
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    # ------------------------------------

    return rag_chain

# --- Streamlit UI êµ¬ì„± ë° ì‹¤í–‰ ---
try:
    rag_chain = load_rag_chain()
    st.set_page_config(page_title="ê·œì • ì§ˆì˜ì‘ë‹µ ì±—ë´‡", page_icon="ğŸ“š")
    st.title("ğŸ“š ì˜ˆì‚° ì§ˆì˜ì‘ë‹µ ì±—ë´‡")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            response = rag_chain.invoke(prompt)
            with st.chat_message("assistant"):
                st.markdown(response)
        st.session_state.messages.append({"role": "assistant", "content": response})

except Exception as e:
    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    st.info("API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€, faiss_index í´ë”ê°€ ì œëŒ€ë¡œ ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
