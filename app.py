import streamlit as st
import os
import asyncio
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, AIMessage

# --- ë¹„ë™ê¸° ì´ë²¤íŠ¸ ë£¨í”„ ì„¤ì • ---
# Streamlit í™˜ê²½ì—ì„œ asyncioë¥¼ ì›í™œí•˜ê²Œ ì‚¬ìš©í•˜ê¸° ìœ„í•¨
try:
    loop = asyncio.get_running_loop()
except RuntimeError:
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ğŸ’° ì˜ˆì‚°ê´€ë¦¬ ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide",
)

# --- ì œëª© ---
st.title("ğŸ’° ì˜ˆì‚°ê´€ë¦¬ ì±—ë´‡")
st.write("ë‚´ë¶€ ê·œì • ë¬¸ì„œ(PDF) ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.")

# --- API í‚¤ ì„¤ì • ---
# Streamlitì˜ secrets ê´€ë¦¬ ê¸°ëŠ¥ì„ ì‚¬ìš©
try:
    google_api_key = st.secrets["GOOGLE_API_KEY"]
except KeyError:
    st.error("Google API í‚¤ë¥¼ .streamlit/secrets.toml íŒŒì¼ì— ì„¤ì •í•´ì£¼ì„¸ìš”!")
    st.info("secrets.toml íŒŒì¼ ì˜ˆì‹œ:\nGOOGLE_API_KEY = \"YOUR_API_KEY_HERE\"")
    st.stop()

# --- ìƒìˆ˜ ì •ì˜ ---
DATA_FOLDER = "data"
FAISS_INDEX_PATH = "faiss_index_combined"

# --- í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ---

@st.cache_resource(show_spinner="ì§€ì‹ ë² ì´ìŠ¤(PDF)ë¥¼ êµ¬ì¶•í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
def build_or_load_vector_store(data_folder, index_path):
    """
    ì§€ì •ëœ í´ë”ì˜ PDFë¥¼ ì½ì–´ FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ê±°ë‚˜, ì´ë¯¸ ì¡´ì¬í•˜ë©´ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    # 1. ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if os.path.exists(index_path):
        st.info("ê¸°ì¡´ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.")
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=google_api_key)
        vector_store = FAISS.load_local(
            folder_path=index_path,
            embeddings=embeddings,
            allow_dangerous_deserialization=True
        )
        return vector_store

    # 2. ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    st.info("ìƒˆë¡œìš´ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    all_documents = []
    pdf_files = [f for f in os.listdir(data_folder) if f.endswith('.pdf')]
    
    if not pdf_files:
        st.error(f"'{data_folder}' í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. PDF íŒŒì¼ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        st.stop()

    for pdf_file in pdf_files:
        loader = PyPDFLoader(os.path.join(data_folder, pdf_file))
        documents = loader.load()
        all_documents.extend(documents)

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    texts = text_splitter.split_documents(all_documents)
    
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=google_api_key)
    vector_store = FAISS.from_documents(texts, embeddings)
    vector_store.save_local(index_path)
    
    return vector_store

def create_retrieval_chain_from_vector_store(vector_store):
    """
    VectorStoreë¥¼ ê¸°ë°˜ìœ¼ë¡œ Retrieval ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash-latest", google_api_key=google_api_key, temperature=0.1)
    
    prompt = ChatPromptTemplate.from_template("""
    ë‹¹ì‹ ì€ ì œê³µëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

    **ì¤‘ìš” ì§€ì¹¨:**
    1.  **ë‚´ìš© ê¸°ë°˜ ë‹µë³€:** ì•„ë˜ì— ì œê³µëœ <context> ë‚´ìš©ë§Œì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. <context> ë‚´ìš©ì´ ì—†ë‹¤ë©´ ëª¨ë“  ê·œì •ì§‘ì„ ìƒì„¸í•˜ê²Œ ì‚´í”¼ê³  ìµœëŒ€í•œ ì¡°í•©í•´ì„œ <context>ì™€ ìµœëŒ€í•œ ìœ ì‚¬í•˜ê²Œ ë§Œë“¤ì–´ ì£¼ì„¸ìš”
    2.  **í‘œ(Table) ë°ì´í„° í™œìš©:** <context>ì— í‘œ í˜•ì‹ì˜ ë°ì´í„°ê°€ ìˆë‹¤ë©´, ê·¸ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
    3.  **ë‹µë³€ í˜•ì‹:** ë‹µë³€ì€ ìµœëŒ€í•œ ìƒì„¸í•˜ê³  ëª…í™•í•˜ê²Œ, ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    4.  **ì •ë³´ ë¶€ì¬ ì‹œ:** ë§Œì•½ <context> ì•ˆì— ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, "ì œê³µëœ ë¬¸ì„œì—ì„œëŠ” í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³ ë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

    <context>
    {context}
    </context>

    [ì‚¬ìš©ì ì§ˆë¬¸]
    {input}

    [ë‹µë³€]
    """)
    
    document_chain = create_stuff_documents_chain(llm, prompt)
    retriever = vector_store.as_retriever()
    retrieval_chain = create_retrieval_chain(retriever, document_chain)
    
    return retrieval_chain

# --- ë©”ì¸ ë¡œì§ ---

# 1. Vector Store ìƒì„± ë˜ëŠ” ë¡œë“œ
vector_store = build_or_load_vector_store(DATA_FOLDER, FAISS_INDEX_PATH)

# 2. Retrieval ì²´ì¸ ìƒì„±
retrieval_chain = create_retrieval_chain_from_vector_store(vector_store)

# 3. ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”! ë‚´ë¶€ ê·œì • ë¬¸ì„œì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.")]

# 4. ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for message in st.session_state.chat_history:
    if isinstance(message, AIMessage):
        with st.chat_message("AI"):
            st.write(message.content)
    elif isinstance(message, HumanMessage):
        with st.chat_message("Human"):
            st.write(message.content)

# 5. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    st.session_state.chat_history.append(HumanMessage(content=user_query))
    with st.chat_message("Human"):
        st.markdown(user_query)

    with st.chat_message("AI"):
        with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            response = retrieval_chain.invoke({"input": user_query, "chat_history": st.session_state.chat_history})
            answer = response.get("answer", "ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            st.write(answer)
            st.session_state.chat_history.append(AIMessage(content=answer))

